<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据库 on Gavin&#39;s Blog</title>
    <link>https://wushaoqiang.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
    <description>Recent content in 数据库 on Gavin&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 06 Oct 2019 14:48:50 +0800</lastBuildDate>
    
	<atom:link href="https://wushaoqiang.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Leader Election</title>
      <link>https://wushaoqiang.github.io/posts/database/raft/leader-election/</link>
      <pubDate>Sun, 06 Oct 2019 14:48:50 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/raft/leader-election/</guid>
      <description>在这里总结一些Leader Election的Case，通过例子来理解Raft的Leader Election或许会更有印象
下面用到的term是指任期值，index是最后一个committed log的位置
大家的Term和Index都相同 当大家的term和index都相同的时候，某一个Follower长时间未收到Leader的心跳发生timeout，就会变成candidate，并且term = currentTerm + 1， 这个时候这个candidate就会号召大家为它投票
投票是按照两个依据来选择是否投票的
 投票请求(RPC)带来的term一定要大于currentTerm，这样节点才知道这是新的一轮投票了
 满足上面条件后，还需要检测请求带来的lastLogIndex以及lastLogTerm以确保candidate拥有比自己新或者和自己一样的状态
  主要满足这两个条件，拥有投票权的节点就会给这个candidate投票
投票是需要majority节点同意的
在我们假设term和index都相同的前提下，发起选举，那么就会有谁先发起谁就非常大概率当Leader
Term相同，Index不一样 我们假设有两个candidate在竞选Leader，candidate1.index &amp;lt; candidate2.index
也就是说candidate2拥有更加新的状态，我们来模拟一下竞选过程
candidate1和candidate2都会向所有节点发起投票请求(RPC)，candidate自己是给自己投票的
那么其它节点如何判断呢？
其实还是上面的那两个依据，不记得请往上面翻一翻
term相同，那么它们都会比currentTerm大(通过)
第二个是比较index，由于Raft会保证committed会在majority上，因此candidate1肯定会被majority拒绝(可能会得到一小部分未更新的节点的投票)
所以candidate2会得到majority的投票，因此成为Leader
结论就是term值一样的candidate，index新的会赢
Term不一样，Index相同 这种情况是term大的会赢
假设candidate1.term &amp;lt; candidate2.term
这一部分我的理解可能不一定正确
因为对于所有server来说，接收到请求里的term要比自己的term大，都会变为Follower，因此我觉得candidate1 在接收到 candidate2的term时，会转换为Follower，这个时候candidate1就像是被迫离场一样
Term不一样，Index不一样 这里假设Leader.term &amp;lt; Candidate.term 但是 Leader.index &amp;gt; candidate.index
这个时候Leader收到了比自己term大的term，因此转换为Follower
但是因为candidate的index不是最新的，因此它不能够得到majority的投票，因此它会再次超时并且sleep一段时间
这个时候之前的Leader term已经是追上了，因此参加选举，这个时候满足选举投票的两个条件，因此再次成为Leader，并且宣布自己是Leader，所以之前的candidate看到有人宣布了Leader，就会放弃选举，变成Follower
不严谨 以上只是读者自己在看Raft Paper以及一些参考的理解，不一定是严谨的，有疑惑的地方还是参照更加官方的资料</description>
    </item>
    
    <item>
      <title>Tips</title>
      <link>https://wushaoqiang.github.io/posts/database/raft/tips/</link>
      <pubDate>Sat, 05 Oct 2019 20:25:51 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/raft/tips/</guid>
      <description>大概情况 今天看了Raft Paper，这是第一遍，我觉得自己还是有很多地方没有理解到位的(尽管我看了将近五个小时)
所以先是记录一下tips，后面重新回来看的时候再追加一下细节(或者还可以结合一下源码)，在raft官网上有相应的源码实现
tips 整体来理解Raft 当Leader接收到来自client的非读请求时，它会先记录在自己的log里面，然后再并发传递给Followers Server，一旦传递给了majority，那么每一个Server都会将log里面的东西放到state machine去执行，结果也将返回给client
先理解一些专有名词  term是描述一个版本号的，越大代表版本越新
 log entry就是我们要保证一致性的信息，整个算法核心就是如何让每一个节点上的log entry一致
 index是索引，节点上面存的log entry都是具有唯一标识的，这个标识就是由term和index来组成，这里可以简单理解为log entry所在的位置
 AppendEntries RPC代表Leader向Followers发送log entry(也可能是心跳)的RPC调用
  一些规则 对所有server来说
 自身的commitIndex &amp;gt; lastApplied，那么就会lastApplied++，然后加入到state machine里
 只要接收到的term比自己的currentTerm大，那么就更新currentTerm，并且转换为Follower
  对于Follower来说
 要处理来自Leader和Candidate的请求
 如果因为没有收到AppendEntries而发生timeout或者给某一个candidate投票了，都会转换为candidate
  对于Candidate来说：
 在选举期间：
 currentTerm++
 给自己投票
 重置election timer
 给其它server发生RequestVote请求
  如果接收到了来自majority的投票，成为Leader
 如果收到了来自新Leader的AppendEntries，成为Follower
 如果过了election timeout的时间，开始新一轮竞选
  对于Leader来说：
 如果是赢得竞选，则发生空的AppendEntries(心跳)来告知其它server，并且持续发送心跳来维护自己Leader地位</description>
    </item>
    
    <item>
      <title>Safety Argument</title>
      <link>https://wushaoqiang.github.io/posts/database/raft/safety-argument/</link>
      <pubDate>Sat, 05 Oct 2019 19:11:27 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/raft/safety-argument/</guid>
      <description>起因 笔者在看Raft Paper的时候，遇到一个比较有意思的证明过程，不过这个证明过程对上下文有着紧密关系，因此在这里想用简单点的逻辑进行描述
这个证明有意思的在于，它通过引出矛盾来证明这个结论是正确的，也算是一种反证法吧
Let&amp;rsquo;s Go 这里证明的是，通过Raft选择出来的Leader，一定拥有最新的committed
假设一下 这里假设有两个Leader，分别为Old Leader，New Leader。
我们假设New Leader在被选举出来的时候并没有最新的committed，什么意思呢，也就是说Old Leader在Crash之前已经commit了一个log，但是这个log并没有在New Leader里
我们知道，要commit一个log需要majority的followers同意。然后，选举一个新的Leader也是需要majority的candidates同意的。这就给出一个结论
因为两者都需要超过半数的节点同意，因此它们肯定有交集的节点
 注：这里用节点是因为不同的场景会有不同的角色，所以统一称为节点  引出矛盾 交集的节点做了两件事情(按顺序)
 接收到了Old Leader宕机之前的log，并且是committed
 给New Leader投票
  我们知道，选举的时候是有限制的，只有拥有最新committed log的节点才有被选举权，所以给New Leader投票说明New Leader在还没成为Leader之前是有这个committed log的(和前面假设冲突)
或者说，New Leader拥有比这个投票者所知道的更加新的committed log，换句话说，New Leader在之前就已经有更新版本的committed log，但是按照原则，创建这个最新版本log的Leader应该是拥有Old Leader的全部committed log的，所以按道理New Leader也应该要有这个log(所以还是和假设冲突)
结论 所以说，New Leader保证是会拥有Old Leader的所有committed log</description>
    </item>
    
    <item>
      <title>TiDB Server源码分析 SQL Core Layer</title>
      <link>https://wushaoqiang.github.io/posts/database/tidb/tidb-server-source-sql-core-layer/</link>
      <pubDate>Thu, 03 Oct 2019 19:54:52 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/tidb/tidb-server-source-sql-core-layer/</guid>
      <description>还是架构 还是先放一张架构图，当思路不清晰的时候，看一看架构图能够帮我们整理思路
回想一下 上一篇blog是介绍了Protocol Layer，这一层整体思路还是比较简单，只是兼容MySQL协议会产生很多相应的函数方法
应该还记得，在上一篇blog，我有提到Driver这个词，并且看到了它的接口只有一个函数OpenCtx(...)...，从结构图上来将，我们需要将SQL传入到Session Context里面，而OpenCtx就是帮我们从Protocol Layer打开到SQL Core Layer的通道，然后再通过这个通道将数据传入进去。打开后会返回QueryCtx接口，这个接口是我们执行SQL的唯一入口，也就是Protocol Layer到SQL Core Layer的唯一入口
什么时候打开通道 通过编辑器可以发现，server/driver.go里的IDriver接口只在一个函数上有调用
func (cc *clientConn) openSessionAndDoAuth(authData []byte) error { var tlsStatePtr *tls.ConnectionState // 如果是SSL连接，就取出这个连接的状态 if cc.tlsConn != nil { tlsState := cc.tlsConn.ConnectionState() tlsStatePtr = &amp;amp;tlsState } var err error // 打开通道，这里将返回的QueryCtx给到clientConn，它以后就用这个Ctx和SQL Core Layer进行交互 cc.ctx, err = cc.server.driver.OpenCtx(uint64(cc.connectionID), cc.capability, cc.collation, cc.dbname, tlsStatePtr) if err != nil { return err } // 忽略验证过程 return nil }  这个函数也只有两个地方会调用到</description>
    </item>
    
    <item>
      <title>TiDB Server源码分析 Protocol Layer</title>
      <link>https://wushaoqiang.github.io/posts/database/tidb/tidb-server/</link>
      <pubDate>Thu, 03 Oct 2019 15:53:09 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/tidb/tidb-server/</guid>
      <description>简单介绍 最近趁着国庆放假，花点时间来看看TiDB这个工程，关于TiDB我就不介绍了，这一个blog主要是关于如何入手了解TiDB Server层，先来看一下这个架构图
因为TiDB源码还是比较多的，因此也是花了两天时间去看了下源码才准备写这个blog，算是个人的一个记录吧
怎么入手 TiDB-Server的架构图还是非常容易懂的，并且这篇文章只用关心左边Protocol Layer
我们可以简单的从tidb-server/main.go来入手，来简单了解一下基本组成
为了方便看源码，我这里直接贴上来了，为了保持逻辑简单，我建议前几次看的时候把一些关系不大的模块忽略，我只做简单的介绍
func main() { // 解析命令行 flag.Parse() // 如果带有version，则只是输出version if *version { fmt.Println(printer.GetTiDBInfo()) os.Exit(0) } // (可忽略)这里是注册store，会分别注册&amp;quot;tikv&amp;quot;和&amp;quot;mock-tikv&amp;quot; registerStores() // (可忽略)这个是和prometheus相关的 registerMetrics() // (可忽略) 配置，我们暂时可以考虑默认 configWarning := loadConfig() overrideConfig() if err := cfg.Valid(); err != nil { fmt.Fprintln(os.Stderr, &amp;quot;invalid config&amp;quot;, err) os.Exit(1) } if *configCheck { fmt.Println(&amp;quot;config check successful&amp;quot;) os.Exit(0) } // (可忽略) 都只是一些配置 setGlobalVars() setCPUAffinity() setupLog() // If configStrict had been specified, and there had been an error, the server would already // have exited by now.</description>
    </item>
    
    <item>
      <title>Transaction</title>
      <link>https://wushaoqiang.github.io/posts/database/theory/transaction/</link>
      <pubDate>Sat, 28 Sep 2019 19:47:36 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/theory/transaction/</guid>
      <description>事务这个词估计做软件开发的都不会陌生，我们可以简单的理解为：事务是一件事，要么成功，要么失败，而失败是全部失败，并不是局部失败
事务这么流行的原因就是，它帮助软件开发者解决了很多难办的事情：
 数据库可能会在任意时间因为软件或者硬件问题直接挂掉(可能这个时候正在执行一些写操作)
 应用也可能会在任意时间宕机
 网络通信是不可靠的
 可能在高并发下，数据库会发生冲突
  等等，这些事情，如果每一个都要想相应的解决方法，是需要大量的时间以及研究大量的算法，并且需要大量的测试集去验证这些算法实现是有用的
事务是为了将这些事情变得简单点，当出现任何不希望出现的状况，我可以选择抛弃这个操作，然后告诉用户，这个操作失败了。最起码，它在操作失败这件事情上，它是正确的
一般来说，事务会集合多个操作(Insert, Update, Delete)，变成一个操作，提交到数据库里，数据库会帮这些打包的操作看作是一个整体，因此操作到一半的时候发生错误，就会发生回滚，把之前的操作都抹去
那么是否用事务就能解决一切复杂的事情呢？
事务不是完美的，就像一直提到的，在数据库设计这一块，都是有的有舍，并没有完美的东西，因此我们也要很好的了解事务的优缺点。
ACID 相信大家对这个词也是不陌生的，但是其实笔者一开始将里面的各个意思理解错了，现在从先来理解一边
Atomicity 这里的中文虽然叫原子性，但是它和我们平常理解的原子性不一样，它这里并不是描述一个并发的过程
这里是指，一系列的操作被打包成一个事务，如果这个事务具有Atomicity，那么它要么被commit，要么被abort，这也保证了这个事务不会修改一部分数据后失败，能够让client放心的去做retry了
所以可以看出，这个Atomicity并不是在描述原子性，而是在描述操作的abortability，是否拥有abort操作
Consistency Consistency在这里是指一个好的状态，这个好的状态是指你的数据应该不违反规则。
但是在数据库层面，是不知道数据是否有效，所以这就需要开发者在应用的代码上写好事务的Consistency
Isolation 这个才是真正和并发相关的特性，隔离机制，后面也会详细讲讲各种隔离机制，以及它们的优缺点
我们在这里，可以简单的认为，我们可以利用隔离机制，将并发的事务一个个进行执行，这样就能够防止RACE发生，这种隔离机制叫serializable isolation但是，一个个执行是多么的低效，完完全全舍弃了并发的优势，所以下面我们会介绍许多没有如此强保证的隔离机制
Durability 持久化是数据库最根本的目的，一个拥有Durability的事务意味着数据能够被写入到硬盘，这里也运用到了之前所说的log或者一些其它方式来记录操作，这样可以在数据库重启后能够自己恢复
Weak Isolation Levels 因为性能问题，很多软件并不想用像serialzable isolation这种最高级别隔离的机制，因为这样的数据库很可能会在整个系统中称为瓶颈。
Read Commited 最基础的一个隔离机制，它能够给我们保证：
 所有读取的数据都是经过committed的
 写入数据库的时候，你只能够重写以及committed的数据
  但是多个事务在操作多个对象的时候，有可能会因为执行顺序不一样导致，事务之间读取到对方committed后的值
如何实现这个隔离机制呢
一般来说，会有一个row-level lock，每一个写操作都会请求对应行的lock，一个lock也只能被一个事务获取并且一直到它committed或者aborted才释放
那读取数据呢？简单点的我们可以也持有lock，但是我们知道，持有lock的代价是很大的，万一读操作很久，或者写操作很久，整个系统的性能就会受到影响，因此我们需要更好的方法去让读尽可能的不用获取lock
一个方法就是，数据库会帮忙记住lock之前的值，如果读取的时候发现是locked了，那么就那之前的值
Snapshot Isolation 其功能和其名字差不多，Snapshot Isolation的做法就是这个事务读取的数据是从一个快照里面读取的，当然，这个快照是不会被改变的，所以所有的事务都只能看见某一个时间点之前的老数据。
当我们在备份的时候， 我们可能不想在备份的时候，数据还在被修改，状态还是不稳定。所以这个隔离让我们不用担心这些问题。这个隔离机制在很多时候帮助我们很多，我们不用担心它有各种奇怪的问题，因为它已经是固定的了
其实Snapshot的实现机制和Read Committed差不多，也是通过lock来控制写入操作，然后读是不用锁的
 readers never block writers, and writers never block readers.</description>
    </item>
    
    <item>
      <title>Partition</title>
      <link>https://wushaoqiang.github.io/posts/database/theory/partition/</link>
      <pubDate>Sat, 28 Sep 2019 16:30:19 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/theory/partition/</guid>
      <description>Partition And Replication 之前在学习Replication的时候，我们可以简单理解为副本集，也就是数据的复制
但是如果数据量很大，然后还复制几分，那不就上天了。Partition提供一种叫分片的方法，能够有效的将数据分隔存储在不同的节点
顺便说一下，默认的partition每个节点上的数据就只有该节点有，其它节点是没有的，也就是说，数据很可能会因为某一个结点不可用而导致该部分数据不可读取
这个时候我们可以选择将Replication和Partition结合起来用，你可能会问这样的一个问题：那数据不是还是复制了好几份了吗?
在Replication里，数据可以认为是相等的，假设我有5个节点，每个节点5TB的数据，总共25TB
在Partition和Replication结合起来用，会有多少呢？我们来算一下
首先，我们有5TB的数据，分片成5份，每一份1TB，每一份再通过Replication来复制到另外两个节点，所以每一份数据实际上有3份，也就是15TB。
这里的巧妙之处在于，你并不用每台机器都要有，备份只需要根据你集群的大小来选择合适的备份数量即可
How to partitioning the data 我们分片要有依据，如果随便存储，那么到时候不知道往哪查找了
我们可以像字典一样，用某一个key的区间作为一个partition，用区间作为区分有一些优点：
 有序，这样在查找的时候，可以按照区间大小一次性取出大量数据(还记得LSM-Tree)
 每个partition的区间大小可以自己指定
  但是也有一些缺点：
 分片有可能严重倾斜，有一些节点已经Overload，而别的节点却很闲  Partitioning by Hash of Key 为了解决Hot Spot问题，我们可以采用随机性较强的哈希函数对每一个key进行一次Hash，再进行分片，这样在大概率上是平均分配给每个节点的
虽然解决了一些问题，但是上面的有序性就被破坏了
我们知道，数据被分散了情况下，读取就会变得越来越麻烦，可能一次查询，就要用到许多的partition，所以也是有很多缺点
Partitioning and Secondary Indexes Secondary Indexes不能唯一标识一个实例，它可以是一个颜色，一个城市等等，许多人可能都生活在一个城市，所以一个城市并不能标识哪个人
这里主要有两种方法将数据库分片，并且是带上Secondary Indexes的
 document-based partitioning
 term-based partitioning
  这两种不同的Secondary Indexes主要的区别在于，document-based只的对它当前节点的数据进行索引
而term-based是对整个集群的索引
我们来看一下它们在读写方面的优劣情况
在写的时候，document-based理论上会有更好的性能
在对一个数据进行更新的时候，document-based只需要修改被更新的partition里的索引，而term-based则可能需要修改多个partition里面的索引
在读的时候，term-based理论上会有更好的性能
因为document-based的索引是分开在各个partition的，所以查询的时候有可能要遍历所有的partition，而term-based因为某些索引集中在一个partition，所以很快能够找到索引值
Rebalancing Partitions 我们无论是新增节点还是删除节点，都需要做这件事情
有一个方法可能大家都听过&amp;ndash;mod
这个方法会导致节点变动时，里面的数据会大量变动，并不是一个好的选择
下面介绍一种方法fixed number of partitions</description>
    </item>
    
    <item>
      <title>Replication Other Pattern</title>
      <link>https://wushaoqiang.github.io/posts/database/theory/replication-other/</link>
      <pubDate>Sat, 28 Sep 2019 16:20:50 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/theory/replication-other/</guid>
      <description>在之前，我着重介绍了一下One Leader的这种Replication模式，其实还有
 Multi Leader
 Leaderless
  后面会写专门的blog去介绍一下这两种情况
现在先简单的了解一下
Multi-Leader这种模式，它可以往Leader上发起写操作，也就是多个节点都可以发生写操作，然后再广播给其它Leader和Followers
Leaderless这种模式，写是写到多个几点上，读也是从多个节点上读，然后通过一些机制取出比较新的数据(也就是排除旧数据)
Multi-Leader咋一听好像相对One-Leader这种模式有更好的写性能，好像看起来是这样的，但是关于冲突方面的奇奇怪怪的问题非常多，也非常难。因此也有很多劣势
Leaderless也是，因为可以多个地方写，那么就会有并发的冲突，如何解决这些冲突就变得很重要了
因此One Leader目前看来还是最多人用的一个，因为它不用太多考虑并发冲突问题</description>
    </item>
    
    <item>
      <title>Replication One Leader</title>
      <link>https://wushaoqiang.github.io/posts/database/theory/replication-one-leader/</link>
      <pubDate>Sat, 28 Sep 2019 15:00:54 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/theory/replication-one-leader/</guid>
      <description>在之前的blog里，我也有大概说过关于单点故障等场景，但是大多数描述都是假设运行在单机上的
在这blog里，我们关心的系统是由多个节点组成的
Replication可以简单理解为副本集模式，它能够在多个节点上拥有同样的数据
Why We Need Multi Machines 之前有讲过一些点：
 高可用
 高扩展
 以及单点容忍
 低延迟，低延迟可能是因为集群的方式处理请求更快，也可能是物理主机理用户距离比较近
 提高读取性能
  One Leader and Followers 在MongoDB里，你可能会发现它们叫PRIMARYandSECONDARY，意思都是一样
One Leader可以说是没那么复杂的一种模式
它们的运作模式也比较简单
在多台机器上运行同一个进程，这不同的进程就组成了一个cluster，cluster里面有且仅有一个Leader Leader是所有写操作的入口，当Leader在写入本地的时候，它也会将自己的Replication Log或者Change Stream(可以抽象成Leader给Followers发的写请求)发给集群上的Followers，这样Followers就能够更新自己的数据，和Leader保持一致
而读操作可以从Leader上读，也可以在Followers上读。不同的是，Leader上的数据一定是最新的，而Followers上的数据有可能还没同步过来(在异步的通信方式下)，就像上面说的，同步是通过请求来的，谁也不能确保通信不出问题
Synchronous Versus Asynchronous Replication 同步和异步拥有很大不同的特性
同步意味着数据需要存入到每一个节点上，这个操作才算完成。如果其中一个节点因为网络问题，连接不上，那么整个系统就hang在这里不动了。所以一般情况下，我们不会选择同步的方式来处理数据
异步意味着持久性会受到影响，为什么呢？设想当写操作还在Leader上的时候，Leader挂了，这个时候数据就完全丢失了，因为当前集群上没有一个节点拥有该份数据。
半同步，我们折中一下双方的优劣，可以得到半同步，我们假设大部分节点都是正常的，这样只要有一定数量的节点收到了数据并且写入，那么我们就可以认为该数据已经得到了备份，这个时候Leader可以告诉外界，这个数据被存储好了
Setting Up New Followers 有时候为了更好的服务，需要增加节点
这个时候节点是没有任何数据的，我们需要让这个节点也能够处于服务状态的话，就必须通过复制数据给到这个节点
How?
传统的想法，直接拷贝文件行不行？
 是不行的，当这个系统是在运行状态，可能有很多中间的状态以及一些文件还是不完整的时候，我们直接拷贝文件很有可能这个文件都无法被解析。所以如果要这样做，可能需要将服务先关了，这样可以防止以上情况。但这又违反了系统的可用性，总不能加个节点就要关服拷贝吧  正确而又比较优雅的做法是利用隔离机制
 有一种隔离机制可以产生出一个快照(Snapshot)，这个快照一旦产生出来就不会改变了，因此新的节点完全可以按照这个快照来构建，然后Leader也不会因为这个新节点加入而停止服务。当新节点完成了快照的恢复，它就会向Leader拿Replication Log，也就是快照之后的数据更新，这样慢慢一步步赶上进度，最终可以像其它节点一样工作了。  Failover 在Followers节点挂了的时候，我们不会用这个词。这个词是描述一个cluster的Leader挂了
当发生failover，我们应该要有相应的failover机制，一般情况下包含这几步
 确定Leader真的挂了，因为许多不可控因素，一般情况下判断一个服务是否挂了，可以用超时来判断，如果超时，那么就算进程没有挂，在对方的角度看来，它就是挂了
 当大多数的节点都判断Leader挂了(防止只是follower和Leader断开连接)，那么就开始挑选新的Leader，这里面应该有一个挑选算法，简单点就是投票机制，票数最多的节点当Leader。当然，每个Follower的票权也可以配置成不一样的。
 重新配置整个集群，使用新的Leader代替旧的Leader，旧的Leader就算后面重新连接，也需要Step Down成为一个Follower
  不够，Failover没有想象中的那么简单，它会在一个高并发的系统上引发很多问题，我这里先不打算说太多(分布式系统的奇怪东西太多了)</description>
    </item>
    
    <item>
      <title>Storage and Retrieval</title>
      <link>https://wushaoqiang.github.io/posts/database/theory/storage-and-retrieval/</link>
      <pubDate>Sat, 28 Sep 2019 10:42:09 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/theory/storage-and-retrieval/</guid>
      <description>数据库简单理解，就为了两件事情：存储和读取
So, Let&amp;rsquo;s keep that simple
Index 索引是与我们主要的数据分开的，我们可以创建索引，删除索引，这都不会影响我们的主要数据
索引最初的目的是为了加快查询操作。但由于有除了主要数据之外的索引数据，因此我们在写入数据库的时候 就要维护多份数据(既要写入我们的主要数据，还要写入相应的索引数据，或者维护索引)，所以一般情况下加索引会 对写的性能有所影响
所以，我们需要根据应用场景来决定是否加索引，这也是开发者应该知道的一些概念
下面简单介绍一下索引种类以及原理
Hash Indexes 其实和我们平时用编程语言里的哈希表有点类似
在Go里，是一个叫做map的数据结构
Go map 如何读写 接收到一个Key 对key进行Hash 通过Hash找到是哪一个bucket 取Hash的前8Bit做一个快速比较 找到bucket的内存(可以进行读写了)  我们可以简单将这个索引比作成一个offset，每一个offset都是某一个数据相对某一个内存的偏移量，这样我们就可以直接读取到该数据，而不用从头开始查找了。这是一个append-only的形式，在这种形式下，我们只需要关注最近的那个offset即可，在数据越来越大的时候，我们可以通过合并，将失效的数据删除
Append-Only咋一眼看去很浪费空间，但它也有独特的优点值得关注：
 相对于随机读写(也就是in-place)，它具有更好的性能
 更好处理恢复
  但是随着时间推移，这个索引变得越来越大，以至于要存入硬盘中，这样，索引相应的性能就会受到很大的影响
并且Hash Index对取一批数据的操作是很不友好的
SSTables and LSM-Trees SSTables = Sorted String Tables
SSTables相对上面说的Hash有很大的优势，不过我们先看一下它需要满足的条件
在上面我们可以看到k-v是直接加进来的，对SSTables，我们规定这些
 k-v是按照key排序的
 每一个key在merge之后的segment都只出现一次
  思考一下，每一个segment都是内部有序的，当我们要合并segment的时候，像什么算法？
我们要清楚知道，每一个segment是有顺序产生的，也就是说相同的key在不同的segment里面也是可以区分先后的
在这种有序的情况下，我们还可以解决上面Hash Index的一个内存爆满问题
因为我是有序的，所以我不一定要知道某一个具体key的内存地址，我可以知道在它附近的key，并且根据排序来找到我想要的key，这样我们就可以极大减少存储在内存里的索引
由于是有序的，我们可以针对一些连续的扫描做很大的优化
说了这么多，都只是介绍，那具体怎么实现呢？
回想一下它需要的第一个条件&amp;ndash;有序
我们都知道，现在有平衡树可以帮我们做到这一点
 RB-Tree
 AVL-Tree
  然后归并算法可以帮我们解决segment合并的问题</description>
    </item>
    
    <item>
      <title>Data Model and Query Language</title>
      <link>https://wushaoqiang.github.io/posts/database/theory/data-model-and-query-language/</link>
      <pubDate>Fri, 27 Sep 2019 23:41:42 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/theory/data-model-and-query-language/</guid>
      <description>Different Between SQL and NoSQL 我们到目前为止，市面上主流的数据库还是环绕着关系型数据库和非关系型数据库，当然也还有别的，但是我们主要对这两个进行对比
 关系型数据库，发展到今天已经是数据库的一号大哥了，它相对NoSQL的优点有：   Many-to-One
 Many-to-Many
 利用外键优势
 冗余少
  这里所说的Many-to-*， 其实就是一个外键的引用，在写入数据库的时候，只需要写入外键的唯一标识(一般是某某ID)就能够在读取的时候，通过Join来得到完整的数据。这样做有一点好处就是，当某一个被多出指向的值需要改变的时候，只需要在哪个table里面改，而外面用的ID还是不变的。这在NoSQL里面是需要遍历update一次的，当数据量非常大的时候，这个操作很可能就会有奇怪的问题出现。
 非关系型数据库，是一个比较年轻，又很火的数据库，它主要是有以下优点：   读取快
 弹性的数据结构
 数据之间不会互相影响
 易横向扩展
  非关系型数据库会更加适用于一些读多写少的场景，它读取快是因为它不用像关系型数据库这样去跨表查询，所有数据都在一个document上。但是这也带来一些缺点：重复数据反复出现造成冗余；批量修改的时候需要update多个document；如果只是需要document的某一个字段，可能也要load整个document(现在已经有数据库支持projection了)
并且，我们在使用的时候可以发现，关系型数据库对数据结构是严格把控进入的(strict write)，而非关系型数据库则是读取解析到程序的时候严格把控的(strict read)
还是那句话，根据应用场景进行选择，到底哪个更加贴合实际
引用书里的一句话
 It&amp;rsquo;s not possible to say in general which data model leads to simpler application code; it depends on the kinds of relationships that exist between data items
 现在的又出现了NewSQL，是将很多SQL和NoSQL的优点集合在一起，既有SQL的查询特性，又有NoSQL的横向扩展特性</description>
    </item>
    
    <item>
      <title>Foundations of Data System</title>
      <link>https://wushaoqiang.github.io/posts/database/theory/foundations-of-data-system/</link>
      <pubDate>Fri, 27 Sep 2019 22:18:53 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/theory/foundations-of-data-system/</guid>
      <description>我们要知道，不同的数据库系统拥有着不同的特性，因此在不同的应用场景下会根据应用所需的特性来选择数据库系统，这也是开发者对数据库必须要了解的地方
这一blog主要是覆盖三个方面
 Reliability
 Scalability
 Maintainability
  Reliability 一般来说，我们希望我们的软件
 正确执行我们所期望的
 就算user操作失误，也能一定程度上容忍
 性能在合适的压力下是好的
 系统可以防止外界未授权侵入
  下面我想先解释一下两个经常搞混的名词
 Fault，这个词是用来描述整个系统中的某一个部件(模块)出现了问题。当然，如果系统就只是一个模块，那么也就等价于Failure了，但是当今众多系统中，基本都由多个模块组成。
 Failure，这个词是用来描述整个系统出了问题，说明系统不可用了
  所以我们要打造的是一个Fault-tolerance的系统，以防止单个模块出问题影响整个系统
用具体的例子说模块出问题就是，将某一个进程杀掉，看看整个系统有没有因此而不工作了(设想中是要工作的)
Hardware Fault 硬件出错，其中包括
 内存满了
 断电
 磁盘损坏
  &amp;hellip;
只要是电子原件，都会有坏的可能
所以，如果软件对可用性要求非常苛刻，那么将服务部署在多台机器上是必不可少的，这也是常说的避免单点故障。而且，多台机器部署，在对服务进行升级的时候，可以控制在对外无感知的情况下升级。也就是帮天上的飞机换轮胎
但是，硬件错误，一般只会是单个出错，同时出错的概率是非常低的(自然灾害除外)，所以一般来说，系统应该能够容忍少部分机器进入宕机的状态
Software Fault 是人写的软件，都会有Bug。还记得一句话
 你以为Hello World就不会有Bug了吗，等什么时候链接器，编译器出现Bug了，就连Hello World这样的程序也跑不过
 所以在设计一个系统的时候，绝对不能假设某一个模块是没问题的，哪怕它的代码再少
那我们应该怎么做可以最大程度减少Failure的可能性呢：
 设计这个系统的时候需要有容忍性的设计
 测试，必不可少的
 隔离，也就是一个模块的Fault不应该引起其它模块的Fault
 容忍宕机重启操作
 有观测整个系统的Monitor(可能是一些Web，或者命令行)
  &amp;hellip;等等</description>
    </item>
    
    <item>
      <title>Mongodb Replica Set Deployment</title>
      <link>https://wushaoqiang.github.io/posts/database/mongodb/mongodb-replica-set-deployment/</link>
      <pubDate>Thu, 30 May 2019 20:05:21 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/mongodb/mongodb-replica-set-deployment/</guid>
      <description>Before start official document
Today, I worked in company program, using mongodb replica set to specify multiple database servers. And this article is for introducing How to deploy a replica set in our own PC for testing and development
It is almost the same for deploying on different host which it used for production
Required I assume you already know how to use mongodb(e.g. mongod,mongo etc.)
The version of my mongodb is 3.</description>
    </item>
    
    <item>
      <title>Mongodb Installation And Config</title>
      <link>https://wushaoqiang.github.io/posts/database/mongodb/mongodb-installation-and-config/</link>
      <pubDate>Sat, 11 May 2019 19:39:42 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/mongodb/mongodb-installation-and-config/</guid>
      <description>总结一下最近在配置MongoDB时遇到的坑吧
首先,在搜索安装教程的时候,很多文章写的是直接安装.tar包,然后解压缩来用
嗯,确实是个直接的方法,用起来也可以,只是稍微麻烦自己去设置环境而已
直接下载tar包 解压后,要将/bin添加到环境变量
然后还要自己创建一个mongod.conf,往里面配置一些东西.或者可以直接在每次开启mongod的时候加入参数(比较麻烦)
这里是我初步的一个配置文件
# mongod.conf # for documentation of all options, see: # http://docs.mongodb.org/manual/reference/configuration-options/ # Where and how to store data. storage: dbPath: /home/shelljo/mongodb/data/db journal: enabled: true # engine: # mmapv1: # wiredTiger: # where to write logging data. systemLog: destination: file logAppend: true path: /home/shelljo/mongodb/log/mongod.log # network interfaces net: port: 27017 bindIp: 0.0.0.0 # how the process runs processManagement: timeZoneInfo: /usr/share/zoneinfo security: authorization: enabled #operationProfiling: #replication: #sharding: ## Enterprise-Only Options: #auditLog: #snmp:  其实这里面还遇到一些别的坑,不太记得了,我搜索了几篇关于安装的教程都是这个样子</description>
    </item>
    
    <item>
      <title>Mongodb Role</title>
      <link>https://wushaoqiang.github.io/posts/database/mongodb/mongodb-role/</link>
      <pubDate>Sat, 11 May 2019 19:39:35 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/mongodb/mongodb-role/</guid>
      <description>参照 User Management Methods
build-in role
这篇文章主要介绍一下关于role的概念,希望读者还是以官网为主,本文为辅
简介 毫无以为,设置role是为了方便管理权限问题,保证数据库的一个安全使用(不然谁都可以删库跑路那还怎么搞)
所以这也算是一个很必要知道的东西
本文只讨论build-in role,不讨论自己设计的role
笔者会一一尝试每一个role
首先 MongoDB对普通的数据库只能添加database user and database administration的role
对admin数据库,则可以添加任何其它类型的role
Database User Role read 简单来说就是只提供对某个数据库读的权利(细节可以上官网上看具体描述)
例如db.collections.find()
我们如何添加呢,这里简单讲一下,后面的都一样
use admin //进入admin database db.createUser({user:&amp;quot;%s&amp;quot;,pwd:&amp;quot;%s&amp;quot;,roles:[{role:&amp;quot;read&amp;quot;,db:&amp;quot;%s&amp;quot;}]})  其中%s是大家自己选择的意思
readWrite 同上多了写的权限
Database Administration Roles dbAdmin 提供权限运行管理类的任务
例如schema-related tasks,indexing and gathering statistics
但是这个role不能够管理user and role management
userAdmin 提供能够在当前database修改roles和users的权利
注意:这样的一个权限代表着它是这个database的superuser,如果在admin database上设置了这种权限意味着间接提供了超级权限(可以看到集群的数据库了)
所以用这个权限的时候要小心点
dbOwner 这个就集成了readWrite,dbAdmin and userAdmin
Cluster Administration Roles 由于笔者对集群化了解还比较浅薄,这里就直接做一些简单翻译
这些administration就不像之前那样是指定某一个数据库了,这是管理整个系统的role
clusterAdmin 这是cluster的最高权限,结合了clusterManager,clusterMonitor,hostManager,additionally dropDatabase action
这是一个可以删库的权限,可见其权限很高了吧</description>
    </item>
    
    <item>
      <title>Mongodb Data Modeling Introduction</title>
      <link>https://wushaoqiang.github.io/posts/database/mongodb/mongodb-data-modeling-introduction/</link>
      <pubDate>Fri, 10 May 2019 18:54:43 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/mongodb/mongodb-data-modeling-introduction/</guid>
      <description>原文
Flexible Schema 不像SQL的数据库一样,Mongodb不需要我们准确定义一个数据格式的规范
也就是说,一个collection里面的document不一定要每个字段都一样,我们也可以实时的更新document的字段(增加或减少)
当然,有些时候为了让数据保持统一,Mongodb也可以让我们自定义collection的validation
Document structure  how the application represents relationships between data
 Embedded Data 这是官方推荐的一种数据结构
 For many use cases in MongoDB, the denormalized data model is optimal.
  This data model facilitates atomic operations.
 当一个写操作(insertOne or insertMany),对每一个document的修改都是atomic,但是并不是每一次改一个document
References 这种就又是关系型了
Data Use and Performance 当我们更侧重最近的数据的时候 &amp;ndash;使用capped collection
如果是侧重全局数据的读取 &amp;ndash;使用索引会增加性能
Document Growth and MMAPv1 当document size超过容量的时候,MongoDB会扩容</description>
    </item>
    
    <item>
      <title>Mongodb Schema Validation</title>
      <link>https://wushaoqiang.github.io/posts/database/mongodb/mongodb-schema-validation/</link>
      <pubDate>Fri, 10 May 2019 16:06:32 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/mongodb/mongodb-schema-validation/</guid>
      <description>Schema Validation MongoDB 提供了模式验证,就像SQL里面的结构类型检查一样
提前说一下,这些validation不能够设置在admin local config数据库,也不能设置在以system.*为名的collection
如果是还未创建的collection
 use db.createCollection() with the validator option.
 如果是已经创建了的collection
 use collMod command with the validator option.
 这里还提供了两个options
validationLevel 控制检查的程度 模式有两种:strict(default) and moderate,To disable validation entirely, you can set validationLevel to off. validationAction 当不符合规范的时候的响应动作(发出error,直接拒绝,还是warn然后接收) 模式有两种:error(default) and warn.  如果我们要具体一个JSON格式
 use the $jsonSchema operator in your validator expression.
 官网例子
db.createCollection(&amp;quot;students&amp;quot;, { validator: { $jsonSchema: { bsonType: &amp;quot;object&amp;quot;, required: [ &amp;quot;name&amp;quot;, &amp;quot;year&amp;quot;, &amp;quot;major&amp;quot;, &amp;quot;gpa&amp;quot;, &amp;quot;address.</description>
    </item>
    
    <item>
      <title>Mongodb Command</title>
      <link>https://wushaoqiang.github.io/posts/database/mongodb/mongodb-command/</link>
      <pubDate>Fri, 10 May 2019 00:03:44 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/mongodb/mongodb-command/</guid>
      <description>关于数据库和collection的操作 db.createCollection() // create a collection db.dropDatabase() // delete a db show collections // show all collections in db show dbs // show all db use db // create if not exist db.collection_name.drop() // delete a collection  插入操作 db.collection.insert({}) //insert one db.collection.insert([{},{}]) //insert many db.collection.insertMany([{},{}]) //insert many db.collection.insertOne({}) //insert one  查询操作 db.collection.find() //find all documents db.collection.find().pretty //much easier to read db.inventory.find( { status: &amp;quot;D&amp;quot; } ) // selects from the inventory collection all documents where the status equals &amp;quot;D&amp;quot; db.</description>
    </item>
    
    <item>
      <title>SQL vs NoSQL</title>
      <link>https://wushaoqiang.github.io/posts/database/sql-vs-nosql/</link>
      <pubDate>Thu, 09 May 2019 22:05:07 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/sql-vs-nosql/</guid>
      <description>花了点时间去了解了一下NoSQL,总结一下一些概念
SQL: Strcuture Query Language
NoSQL: Not Only SQL
一些概念 ACID 这是关系型数据库遵循的法则
A: Atomatic -all or nothing,要么全部完成,要么回滚什么都不做 C: Consistancy -一致性,系统就算是并发多个的,也必须如同串行事务一样 I: Isolation -用于竟态保护,并行安全,确保只有一个事务在使用系统 D: Durability -once executed, data is immediately saved  CAP 这是Eric Brewer说的,三个指标不可能同时做到,这就是CAP定理
Consistency 一致性 Availablility 可用性 Partition tolerance 分区容错  在分布式服务上,必须要满足P,所以只剩下了C和A选
最常见的是AP组合,一致性靠一个时间窗口达到
因为NoSQL常用在分布式系统上,所以这个概念也非常重要
SQL vs NoSQL 字段(有利有弊) SQL有固定的table字段(field),所以只能够往table里添加固定的结构数据
 优点:开发者知道要往table里面添加什么值,已经清楚table里面有什么具体的field
 缺点:随着业务需求,可能对结构会有所变化,变化麻烦
  NoSQL没有固定的collection字段,collection下面是document(一般是json),document里面的数据可以拥有不同的字段
 优点和缺点刚好和上面相反  关系(有利有弊) SQL通过table之间的关系来达到分布式数据
 优点:通过一个table将数据连接起来,没有过多的冗余数据
 缺点:对分布式不友好,并且一旦关系多了,会产生混乱
  NoSQL没有关系,全部都是直接存储</description>
    </item>
    
    <item>
      <title>SQL 进阶</title>
      <link>https://wushaoqiang.github.io/posts/database/mysql/SQL-highlevel/</link>
      <pubDate>Tue, 23 Apr 2019 10:25:40 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/mysql/SQL-highlevel/</guid>
      <description>只针对Mysql的SQL语句
##创建TABLE
CREATE TABLE user ( id int PRIMARY KEY, username varchar(255) NOT NULL UNIQUE, password varchar(255) NOT NULL );  约束也可以这样写
CREATE TABLE user ( id int, username varchar(255) NOT NULL, password varchar(255) NOT NULL City varchar(255) DEFAULT &#39;Sandnes&#39; UNIQUE(username) PRIMARY KEY(id) FOREIGN KEY (P_id) REFERENCES Persons(P_id) )  约束  NOT NULL
 UNIQUE
 PRIMARY KEY(NOT NULL和UNIQUE的结合)
 FOREIGN KEY:保证一个表中的数据匹配另一个表中的值的参照完整性
 CHECK
 DEFAULT 默认值，在没有赋值的情况下就是默认值
  NOT NULL 强制不接受NULL，如果不向该字段添加值，就无法插入新纪录或者更新记录</description>
    </item>
    
    <item>
      <title>SQL 基础</title>
      <link>https://wushaoqiang.github.io/posts/database/mysql/SQL-basic/</link>
      <pubDate>Mon, 22 Apr 2019 23:05:06 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/mysql/SQL-basic/</guid>
      <description>笔者之前学了一些基础的Mysql的语法，现在进一步学习
关系型数据库用的语言标准就是SQL，只是不同的数据库有自己的拓展，所以学SQL标准可以说是一举多得吧
非关系型数据库有自己的一套语言
只针对Mysql的SQL语句
SELECT 选定要输出的列
SELECT column_name,column_name FROM table_name;  将所有列输出
SELECT * FROM table_name;  SELECT DISTINCT 如果一个列中包含了很多相同的，比如国家里面有很多人是中国的、日本的等等，我们指向查看有多少种的话，这样看起来很费劲
介绍一个解决这种问题的命令
和SELECT语法基本一样，只是这里不会输出相同的字段
SELECT DISTINCT column_name,column_name FROM table_name;  WHERE WHERE子句用于提取那些满足指定标准的记录
SELECT column_name,column_name FROM table_name WHERE column_name operator value;  例如，我要id大于3的user的id和name字段
SELECT id,name FROM user WHERE id &amp;gt; 3  这里提醒一点，当实例是文本字段需要加单引号，如果是数值字段，就像上面一样直接写就好
WHERE的运算符 WHERE column_name operator value  这里的operator就是运算符的位置
运算符有：
 =,&amp;gt;,&amp;gt;=,&amp;lt;,&amp;lt;= 这些就比较好理解了
 &amp;lt;&amp;gt; 不等于
 BETWEEN 在某个范围，用法WHERE column_name BETWEEN value1 AND value2</description>
    </item>
    
    <item>
      <title>Mysql学习笔记</title>
      <link>https://wushaoqiang.github.io/posts/database/mysql/mysql-basic/</link>
      <pubDate>Sun, 17 Mar 2019 02:14:18 +0800</pubDate>
      
      <guid>https://wushaoqiang.github.io/posts/database/mysql/mysql-basic/</guid>
      <description>安装 sudo apt-get install mysql-server mysql-client
查询是否安装了： sudo netstat -tap grep mysql
安装成功
tcp 0 0 localhost:mysql 0.0.0.0:* LISTEN 31238/mysqld  整个安装过程没有叫输入密码
登录 打开debian.cnf文件： sudo nano /etc/mysql/debian.cnf
# Automatically generated for Debian scripts. DO NOT TOUCH! [client] host = localhost user = debian-sys-maint password = x7McPCywm2p7SsnZ socket = /var/run/mysqld/mysqld.sock [mysql_upgrade] host = localhost user = debian-sys-maint password = x7McPCywm2p7SsnZ socket = /var/run/mysqld/mysqld.sock  这里面有一个叫debian-sys-maint的user
登录debian-sys-maint： mysql -u debian-sys-maint -p</description>
    </item>
    
  </channel>
</rss>